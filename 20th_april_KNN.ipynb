{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd7e92c-17bd-4503-806a-b57690282b52",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59e10f9-a883-4dd1-81e2-2b648d9fe0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN is a supervised Machine learning algorithm used for classification as well as regression purpose which uses K nearest neighbors for predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380e9081-cbdf-4871-9432-82cef7d0e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is one of teh simplest algorithm because we only needs to calculate nearest K distance points, where can be any number greater than 0\n",
    "## Once distance is found out, we take voting of K points and then majority will be classified as prediced output in classification problem while average of all K points is taken as \n",
    "## final output in REgression problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1dfc4e-929c-4a69-8d92-4b6b003a35c7",
   "metadata": {},
   "source": [
    "Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54eea3ff-611f-4e48-a78c-c27491132f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A small value of K means that noise will have a higher influence on the result. \n",
    "## arger the value of K, higher is the accuracy. If K is too large, you are under-fitting your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900997e8-f8a1-4113-85f3-dd5195ff7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The value of K can be any number may be 1,2 , 5 etc but the choice can be done more appropriately using hyperparameter tuning,cross validation\n",
    "## Domain Knowledge also helps to find out the better K value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06635a2f-c6b1-498f-9640-e39cbf0a2f5b",
   "metadata": {},
   "source": [
    "Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ac08a2-5b5e-4d6f-9d6d-a36bea05190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN Classifier is for classification where voting of K neigbors is done and majority is taken as final output class\n",
    "## KNN Regressor is used for regression where average of all K neighbors is taken as final output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f7b53-769e-45f7-9142-5ed799a029d9",
   "metadata": {},
   "source": [
    "Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22754c82-b119-4d07-b37e-b47d4ac6b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To measure the performance of KNN different metrics can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030d0b70-006a-49c6-b785-c1b70ad99d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Classificaion purpose\n",
    "## Accuracy Score:\n",
    "## Confusion Matrix\n",
    "## Precision and Recall\n",
    "## F1Score \n",
    "## ROC Curve and AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4b8dcc-3cf3-484d-b3d5-bef856bace65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Regression \n",
    "## r2_score\n",
    "## Mean Squarred Error\n",
    "## Mean Absolue Error\n",
    "## Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa3bd3-0bb9-4a5a-901d-c880313ad1ef",
   "metadata": {},
   "source": [
    "Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9831a22-6121-4999-9ff6-f56ba7d593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The curse of dimensionality refers to the phenomenon where the performance of certain algorithms, including the k-nearest neighbors (KNN) algorithm,\n",
    "## degrades significantly as the number of dimensions (features) in the dataset increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7558b44-266f-413b-8e8d-38ad67eb50c1",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e6f8b5-3071-4e0e-b5b3-15ec51cc2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple way to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b59073-f1d1-4f6b-b335-46c5d46e44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Deleting: We can delete the mising value record or column if large number of missig values are there\n",
    "## 2. Mean/Median Imputation: IN case of Numerical variable we can fill it with mean or median if outliers present\n",
    "## 3.Mode Imputation: In case of categorical variable fill it with mode values\n",
    "## 4. We can also use here KNN to find the nearest data points and fill it wih similar neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee88032-3e0f-44cf-90e6-5ad5129d8366",
   "metadata": {},
   "source": [
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc9e139-fac8-4e72-b850-28474626c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As explained in Questin 3 difference between KNN Classifier and Regressor for which type of problem it can be used\n",
    "## Also how performace is measure is also explained in Question 3 for both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed54f4-8eaa-46a1-b0f8-69786b20f909",
   "metadata": {},
   "source": [
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f71e84-07a8-4e86-b29f-b9f8a492fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strength\n",
    "## It's easy to understand and simple to implement\n",
    "## Adaptability to new data: KNN is considered a lazy learning algorithm because it doesn't require training a model\n",
    "## It's ideal for non-linear data since there's no assumption about underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b17b2f-0a54-4d58-80d9-b6f3695d2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weakness\n",
    "## Associated computation cost is high as it stores all the training data\n",
    "## Requires high memory storage\n",
    "## Need to determine the value of K\n",
    "## Sensitive to irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1aee65-de5b-4fd2-830e-19d115b150a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The above problems can be addressed by\n",
    "## Dimensianality REduction: PCA or feature Selection Methods\n",
    "## Cross Validation and hyperparameter Tuning\n",
    "## Assigning weights to the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de771d-afba-4232-8382-39642983b256",
   "metadata": {},
   "source": [
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "217a36b4-2be9-44f2-8be7-03f5fe277eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Euclidean Distance: This is the shortest  distance between points using a straight line\n",
    "## Formula=sqrt((x2-x1}^2+(y2-y1)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4caa3373-6d99-4291-a4e4-ac1c36664e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manhattan Distance:Manhattan distance, also known as city block distance or L1 distance, measures the distance between two points by \n",
    "## summing the absolute differences of their corresponding feature values. \n",
    "## Distance = |x2 - x1| + |y2 - y1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2ab73-0f56-4b69-99a9-e1f5ce98050a",
   "metadata": {},
   "source": [
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d60ab0cb-c679-47a6-a4bd-016f772d691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature scaling is important in KNN to ensure equal importance of features, prevent bias, improve convergence, and maintain compatibility with other distance-based algorithms.\n",
    "## It helps in obtaining reliable and meaningful results from the KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88973e0a-2b64-4375-9285-5f841d8f0876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
