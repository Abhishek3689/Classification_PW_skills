{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77af226-4683-4297-9046-456356a9e1f3",
   "metadata": {},
   "source": [
    "Q1. What is the curse of dimensionality reduction and why is it important in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd51c0c-6486-40c5-b59c-88c25319bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Curse of dimensionality: Initially if we try to include some important features in teh dataset the performance goes up but as redundant features are get added more \n",
    "## the performance of machine learning algorithm starts going down so the large number of dimensions tends to reduce the accuracy/score of the model.\n",
    "## This is called Curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b40a9-88ec-4ef4-874b-119e934757bb",
   "metadata": {},
   "source": [
    "Q2. How does the curse of dimensionality impact the performance of machine learning algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06812390-ace7-44de-b541-f8dbdafd34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comlexity: AS the dimensions get increased the computational complexity of the problem arises\n",
    "## Feature Redundancy and Irrelevance: High-dimensional data often contains redundant or irrelevant features. Redundant features provide similar information,\n",
    "##     while irrelevant features do not contribute meaningfully to the learning task. \n",
    "## Overfitting : as the dimension increases models learns to irrelevant features rather than capturing underlying pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfd40f-ea9e-4f9a-9ff1-0f9843649f55",
   "metadata": {},
   "source": [
    "Q3. What are some of the consequences of the curse of dimensionality in machine learning, and how do\n",
    "they impact model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4aca5a8-2b8e-438c-8ee5-4dfb2a24c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comlexity: AS the dimensions get increased the computational complexity of the problem arises\n",
    "## Feature Redundancy and Irrelevance: High-dimensional data often contains redundant or irrelevant features. Redundant features provide similar information,\n",
    "##     while irrelevant features do not contribute meaningfully to the learning task. \n",
    "## Overfitting : as the dimension increases models learns to irrelevant features rather than capturing underlying pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03cc4d-a6a9-4ba0-81a2-9c2f3302b0ea",
   "metadata": {},
   "source": [
    "Q4. Can you explain the concept of feature selection and how it can help with dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee2c8ea-fc2d-40dd-a524-c44f9fe6989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature selection is the process of selecting a subset of relevant features from a larger set of available features in a dataset. \n",
    "## It aims to identify and retain the most informative features while discarding redundant or irrelevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574dd034-b8a3-4f66-b404-2e5fa71a2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It helps to reduce computatinal cost as dimesnions will be less\n",
    "## training will be much faster\n",
    "## overfitting issue can be resolved\n",
    "## Improved model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a1d48-b0f1-4ee8-bbd7-559873e85149",
   "metadata": {},
   "source": [
    "Q5. What are some limitations and drawbacks of using dimensionality reduction techniques in machine\n",
    "learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4a74ce-7fe5-47ea-84a0-747991f0400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss of information: There will be some loss of imformation which can affect the performance of model\n",
    "## It can be computationally intensive\n",
    "## Since it requires some transformation of the data , sometimes it becomes difficult to interpret\n",
    "## It may need a lot of processing power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06448bb-57bb-42b8-9d4f-f740854f7a3a",
   "metadata": {},
   "source": [
    "Q6. How does the curse of dimensionality relate to overfitting and underfitting in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909dcb77-9cff-4668-8d90-84bed6ea650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## More the number of dimensions, more would be the variance in the data points, more difficult it becomes to create generalized model and tends to over-fit\n",
    "##  High-dimensional data can make it challenging to capture the intricate relationships between the features and the target variable. \n",
    "##     If the model is too simple or lacks the expressive capacity to capture these relationships, it may underfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd4dc8-b0a0-442b-bb71-dfdbd5fd4356",
   "metadata": {},
   "source": [
    "Q7. How can one determine the optimal number of dimensions to reduce data to when using\n",
    "dimensionality reduction techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb46af8-1ee1-46b8-93f7-17493c84815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Model-dependent approach: Whenever we have a large number of features, we can always perform forward feature selection to determine the most relevant features for the prediction.\n",
    "## For techniques like Principal Component Analysis (PCA), the variance explained by each principal component can be analyzed.\n",
    "## Cross Validation:By performing cross-validation with different numbers of dimensions, you can observe how the model's performance varies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572db6cb-929c-4d28-9e6d-1574bb450306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
