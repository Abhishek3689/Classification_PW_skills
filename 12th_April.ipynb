{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790edecb-9d52-4d9e-807c-ac7c191a2eb7",
   "metadata": {},
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0feb34a5-7992-4606-a455-b05d39c347c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging (Bootstrap Aggregating) is an ensemble learning technique that reduces overfitting in decision trees by generating multiple independent samples\n",
    "## of the training data and fitting a decision tree to each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e079cef0-92da-4592-8437-c50efe410f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By generating multiple independent samples of the training data and fitting a decision tree to each sample, bagging reduces the variance of the model \n",
    "## and improves its generalization performance. This is because each decision tree is trained on a slightly different subset of the data, \n",
    "## so the ensemble of trees can capture more of the variability in the data and produce more robust predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b0c6e-0907-4883-92c9-dc7fd0de0fca",
   "metadata": {},
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7044f645-97ce-4842-90bd-134d66a8eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advantages\n",
    "## The biggest advantage of bagging is that multiple weak learners can work better than a single strong learner.\n",
    "## It provides stability and increases the machine learning algorithmâ€™s accuracy that is used in statistical classification and regression.\n",
    "## It helps in reducing variance, i.e. it avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6844345a-ccfa-4acb-962d-75f02d1a5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disadvantages\n",
    "## It may result in high bias if it is not modelled properly and thus may result in underfitting.\n",
    "## Since we must use multiple models, it becomes computationally expensive and may not be suitable in various use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083c5e1-82c8-4c03-b3fb-b0b5aeaa1c96",
   "metadata": {},
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140ad9d0-fcfc-4f33-bdba-f2432d9004a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generally, the base learner in bagging is a decision tree, due to its high variance and low bias nature. \n",
    "## However, other base learners, such as neural networks, support vector machines, or k-nearest neighbors, can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f61ad1-cc04-4ba7-b2e0-10445fb3930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the base learner has high variance, then bagging can help to reduce the variance by averaging the predictions of multiple models, \n",
    "## which will help to improve the generalization performance of the model.\n",
    "## This is because the variance of the average of a set of random variables decreases as the number of variables increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e237f33d-19a2-4aa5-bf5b-562a49231c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On the other hand, if the base learner has high bias, then bagging may not be as effective in reducing the bias, \n",
    "## as the averaging of multiple biased models will not necessarily reduce the bias. In this case, other techniques such as boosting may be more appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02745a-9e0d-451b-809e-ad9da4f8de5e",
   "metadata": {},
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7741c8f6-9d58-42f1-9371-02899d316a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Yes baggin can be used for both classification and regression tasks\n",
    "## In classification majority of the vote is taken as the final output\n",
    "## while in Regression average of the all the  base model is taken as the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0ae00-c06a-4e44-a2ab-e2e249b434d6",
   "metadata": {},
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9574088d-d449-4d9c-a7f5-8fbadd03dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The ensemble size in bagging refers to the number of models that are trained on different subsets of the training data and combined to make the final prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07dcf521-6675-44a9-80cb-6c7fbf70d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increasing the ensemble size can help to reduce the variance of the bagging model, as the prediction becomes more stable \n",
    "## and less sensitive to the specific subset of training data used to train each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9158840d-d603-483a-80c4-bf2814244f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The optimal ensemble size for bagging depends on various factors, such as the complexity of the base learner, \n",
    "## the size and diversity of the training data, and the desired level of variance reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d41ae6-3135-4771-8875-83ee95c5138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Empirically, a common rule of thumb is to use an ensemble size of 50 to 500 models for bagging, depending on the specific application and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88e015-95ce-4bc6-89da-33e44de5eea6",
   "metadata": {},
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77d50b10-b86e-4c92-8b7e-4159768206a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There can be multiple examples where bagging can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcc38fe-a35d-4561-92fa-8a58578323ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For example, a bagged decision tree model can be used to predict the risk of readmission for patients with heart failure, which is an important measure of healthcare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8febf60-2318-4563-b26c-8f4137c0e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The model would be trained on a dataset of patient records that includes demographic information, medical history, laboratory results, \n",
    "## and other relevant features. The bagged decision tree model would randomly sample subsets of the training data with replacement, \n",
    "## and train multiple decision trees on each subset. The final prediction would be made by combining the predictions of all the decision trees, typically using majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d273567-4a87-4dbc-8ccd-a3eba9374c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
